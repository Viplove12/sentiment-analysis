{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viplove12/sentiment-analysis/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTUY315U5x1N",
        "colab_type": "code",
        "outputId": "de20f2d2-3ef4-4476-8bb4-4ed3001dcd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TjPkfg1Cr8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY_LHh71DThW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dataset=pd.read_csv('/content/drive/My Drive/sentiment analysis (1)/train.csv',encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GADiNhIiZwsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03509050-051c-47ba-92a6-bb7d018a9f10"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMRRpE6BDeLw",
        "colab_type": "code",
        "outputId": "50d2e619-b992-463f-a65c-963f57662300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus=[]\n",
        "print(\"done\")"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K9EJTZg8ZXe",
        "colab_type": "text"
      },
      "source": [
        "## **Data PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P56VwADDpGE",
        "colab_type": "code",
        "outputId": "cbfcd3ef-5810-4595-f4db-37bbd740fba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(0,len(dataset)):\n",
        "    review=re.sub('[^a-zA-Z]',' ',dataset['SentimentText'][i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    ps=PorterStemmer()\n",
        "    review=[ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "all_text=' '.join(corpus)\n",
        "\n",
        "words=all_text.split()\n",
        "print('done')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjg1x0HaYs6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bcac3ba-e282-4973-e114-dc1fda7ee5c8"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "782808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgFmcm_f_Y9H",
        "colab_type": "text"
      },
      "source": [
        "## Encoding (because pytorch take encoded values only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwT_zjG_YqO",
        "colab_type": "code",
        "outputId": "ee1260a4-3281-45b5-b110-5e83dd1d6c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "counts=Counter(words)\n",
        "vocab=sorted(counts,key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "reviews_ints = []\n",
        "for review in corpus:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
        "print('done')"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MRfOcb2YkRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db1b4fe0-2c47-479e-e58e-f4b01af7432a"
      },
      "source": [
        "len (reviews_ints)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Fgn6Hj-V7V",
        "colab_type": "text"
      },
      "source": [
        "## Removing 0 lenght tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyDlZcaLIkm4",
        "colab_type": "code",
        "outputId": "a81a21dc-677e-4a3d-a89c-f85683543e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "\n",
        "    \n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
        "sum=0;\n",
        "\n",
        "#FOR SEQUENCE LENGTH\n",
        "for x in reviews_ints:\n",
        "    sum+=len(x);\n",
        "\n",
        "sum=sum/len(reviews_ints)   \n",
        "\n",
        "#For finding the max length\n",
        "lenght=0\n",
        "size=len(corpus)\n",
        "for i in range(size):\n",
        "    if lenght<len(corpus[i]):\n",
        "        lenght=len(corpus[i])\n",
        "\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "print(len(non_zero_idx))\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "new_labels = np.array([dataset['Sentiment'][ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))\n"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 32\n",
            "Maximum review length: 79\n",
            "Number of reviews before removing outliers:  99989\n",
            "99957\n",
            "Number of reviews after removing outliers:  99957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GipVIgUB-muC",
        "colab_type": "text"
      },
      "source": [
        "## Padding the Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J41E2sAK-d49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features    \n",
        "\n",
        "seq_length = 150\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnSlwoaZACyv",
        "colab_type": "text"
      },
      "source": [
        "##Spliting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TqKqRSo-diI",
        "colab_type": "code",
        "outputId": "34776683-fec2-4529-e15b-88575578a23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtra,ytrain,ytra=train_test_split(features,new_labels,test_size=0.2,random_state=0)    \n",
        "xval,xtest,yval,ytest=train_test_split(xtra,ytra,test_size=0.5,random_state=0)    \n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(xtrain.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(xval.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(xtest.shape)\n",
        "     \n",
        "     )\n",
        "\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(79965, 150) \n",
            "Validation set: \t(9996, 150) \n",
            "Test set: \t\t(9996, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKLHsh-XvRhG",
        "colab_type": "code",
        "outputId": "53c6e8da-6d31-4ed4-faee-539b0f69c6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ytest.shape\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsb4sKGsvRE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-GDIyfHAHWD",
        "colab_type": "text"
      },
      "source": [
        "##Dataloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU1MWodhAGUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(xtrain), torch.from_numpy(ytrain))\n",
        "valid_data = TensorDataset(torch.from_numpy(xval), torch.from_numpy(yval))\n",
        "test_data = TensorDataset(torch.from_numpy(xtest), torch.from_numpy(ytest))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 32\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc2eLpNdpcWS",
        "colab_type": "code",
        "outputId": "890d5f29-8153-47e2-c358-959fb00b98ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(train_loader))\n",
        "print(len(valid_loader))\n",
        "print(len(test_loader))"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2498\n",
            "312\n",
            "312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mNazQkSAoQ8",
        "colab_type": "text"
      },
      "source": [
        "##Checking for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP3P8RP9An0c",
        "colab_type": "code",
        "outputId": "1dc4e55d-fa1e-4b3a-f08a-00353daac5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')\n"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auhakLF2ASOT",
        "colab_type": "text"
      },
      "source": [
        "#Creating the architecture of RNN(using class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSyT58VeAR67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc1 = nn.Linear(hidden_dim, 100)\n",
        "        self.fc2 = nn.Linear(100, 1)\n",
        "        \n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc1(out)\n",
        "        out=self.fc2(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "         # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "         # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:    \n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl79YHB-BEtR",
        "colab_type": "text"
      },
      "source": [
        "##Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzEGumZoBEaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93195f83-af36-4a5a-e361-dd25bb700ef1"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 512\n",
        "n_layers = 3\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print('done')"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6pME7PeBRLL",
        "colab_type": "text"
      },
      "source": [
        "##loss and optimization functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDgqnviYBPKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12ff6418-3880-45b7-b43d-62e8d1757db6"
      },
      "source": [
        "\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "print('done')"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekpwf7OdBTX_",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJTej3hFBWgA",
        "colab_type": "code",
        "outputId": "d3ed8a03-c1b1-4f61-90a2-59c418322a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "# training params\n",
        "\n",
        "epochs = 2# 3 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2... Step: 100... Loss: 0.557674... Val Loss: 0.621793\n",
            "Epoch: 1/2... Step: 200... Loss: 0.615410... Val Loss: 0.597965\n",
            "Epoch: 1/2... Step: 300... Loss: 0.508855... Val Loss: 0.586846\n",
            "Epoch: 1/2... Step: 400... Loss: 0.525422... Val Loss: 0.579808\n",
            "Epoch: 1/2... Step: 500... Loss: 0.595365... Val Loss: 0.580435\n",
            "Epoch: 1/2... Step: 600... Loss: 0.509907... Val Loss: 0.556046\n",
            "Epoch: 1/2... Step: 700... Loss: 0.502599... Val Loss: 0.555449\n",
            "Epoch: 1/2... Step: 800... Loss: 0.587867... Val Loss: 0.564071\n",
            "Epoch: 1/2... Step: 900... Loss: 0.522794... Val Loss: 0.549660\n",
            "Epoch: 1/2... Step: 1000... Loss: 0.623706... Val Loss: 0.547534\n",
            "Epoch: 1/2... Step: 1100... Loss: 0.632756... Val Loss: 0.532119\n",
            "Epoch: 1/2... Step: 1200... Loss: 0.571723... Val Loss: 0.539207\n",
            "Epoch: 1/2... Step: 1300... Loss: 0.581109... Val Loss: 0.529637\n",
            "Epoch: 1/2... Step: 1400... Loss: 0.583958... Val Loss: 0.530410\n",
            "Epoch: 1/2... Step: 1500... Loss: 0.470295... Val Loss: 0.527084\n",
            "Epoch: 1/2... Step: 1600... Loss: 0.540080... Val Loss: 0.526174\n",
            "Epoch: 1/2... Step: 1700... Loss: 0.636326... Val Loss: 0.523434\n",
            "Epoch: 1/2... Step: 1800... Loss: 0.567886... Val Loss: 0.523761\n",
            "Epoch: 1/2... Step: 1900... Loss: 0.487682... Val Loss: 0.522062\n",
            "Epoch: 1/2... Step: 2000... Loss: 0.578384... Val Loss: 0.515702\n",
            "Epoch: 1/2... Step: 2100... Loss: 0.512498... Val Loss: 0.512830\n",
            "Epoch: 1/2... Step: 2200... Loss: 0.379896... Val Loss: 0.511710\n",
            "Epoch: 1/2... Step: 2300... Loss: 0.819759... Val Loss: 0.519438\n",
            "Epoch: 1/2... Step: 2400... Loss: 0.485293... Val Loss: 0.512503\n",
            "Epoch: 2/2... Step: 2500... Loss: 0.377238... Val Loss: 0.521288\n",
            "Epoch: 2/2... Step: 2600... Loss: 0.362332... Val Loss: 0.563492\n",
            "Epoch: 2/2... Step: 2700... Loss: 0.416063... Val Loss: 0.516930\n",
            "Epoch: 2/2... Step: 2800... Loss: 0.264654... Val Loss: 0.521470\n",
            "Epoch: 2/2... Step: 2900... Loss: 0.513121... Val Loss: 0.554069\n",
            "Epoch: 2/2... Step: 3000... Loss: 0.479487... Val Loss: 0.518865\n",
            "Epoch: 2/2... Step: 3100... Loss: 0.557860... Val Loss: 0.519294\n",
            "Epoch: 2/2... Step: 3200... Loss: 0.337992... Val Loss: 0.549528\n",
            "Epoch: 2/2... Step: 3300... Loss: 0.390866... Val Loss: 0.548935\n",
            "Epoch: 2/2... Step: 3400... Loss: 0.570273... Val Loss: 0.523645\n",
            "Epoch: 2/2... Step: 3500... Loss: 0.632177... Val Loss: 0.518212\n",
            "Epoch: 2/2... Step: 3600... Loss: 0.446008... Val Loss: 0.521759\n",
            "Epoch: 2/2... Step: 3700... Loss: 0.464192... Val Loss: 0.529441\n",
            "Epoch: 2/2... Step: 3800... Loss: 0.488647... Val Loss: 0.519876\n",
            "Epoch: 2/2... Step: 3900... Loss: 0.500978... Val Loss: 0.539870\n",
            "Epoch: 2/2... Step: 4000... Loss: 0.582916... Val Loss: 0.520285\n",
            "Epoch: 2/2... Step: 4100... Loss: 0.537990... Val Loss: 0.511768\n",
            "Epoch: 2/2... Step: 4200... Loss: 0.465766... Val Loss: 0.520541\n",
            "Epoch: 2/2... Step: 4300... Loss: 0.385132... Val Loss: 0.510796\n",
            "Epoch: 2/2... Step: 4400... Loss: 0.417664... Val Loss: 0.520121\n",
            "Epoch: 2/2... Step: 4500... Loss: 0.470847... Val Loss: 0.511781\n",
            "Epoch: 2/2... Step: 4600... Loss: 0.343886... Val Loss: 0.522706\n",
            "Epoch: 2/2... Step: 4700... Loss: 0.709780... Val Loss: 0.514001\n",
            "Epoch: 2/2... Step: 4800... Loss: 0.378788... Val Loss: 0.510153\n",
            "Epoch: 2/2... Step: 4900... Loss: 0.661930... Val Loss: 0.509557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83bNBT37CYCG",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK9KqosJE4qf",
        "colab_type": "code",
        "outputId": "ebb0e37a-77be-4115-8f10-d7fb31b5cb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "ypred=[]\n",
        "count=0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    count+=1\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    ##ypred.append()\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    #print(len(pred),len(labels))\n",
        "    ypred.extend(pred)\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
        "\n",
        "#print(len(ypred))\n",
        "ytestt=ytest[:len(ypred)]\n",
        "#print(len(ypred))\n",
        "from sklearn.metrics import f1_score\n",
        "test=np.asarray(ytestt)\n",
        "ypred=np.asarray(ypred)\n",
        "ypred=ypred.astype(int)\n",
        "score=f1_score(ytestt,ypred)\n",
        "print(\"F1 score is: {:.3f}\".format(score))\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "average_precision = average_precision_score(ytestt,ypred)\n",
        "print('Average precision-recall score: {:0.3f}'.format(average_precision))\n",
        "from sklearn.metrics import recall_score\n",
        "recall_score=recall_score(ytestt, ypred)\n",
        "print('Average recall score: {:0.3f}'.format(recall_score))\n"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.529\n",
            "Test accuracy: 0.733\n",
            "F1 score is: 0.554\n",
            "Average precision-recall score: 0.560\n",
            "Average recall score: 0.546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1hG446LpMbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "cnf_matrix = confusion_matrix(ytestt, ypred)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WImHYM9pama",
        "colab_type": "code",
        "outputId": "7b2c92f2-9259-446c-c1db-fd44fe2f1000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cnf_matrix"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1865, 2535],\n",
              "       [2340, 3244]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36zP-hidrHnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}